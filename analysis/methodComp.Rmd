---
title: "Iterative Comparison"
output:
  workflowr::wflow_html:
    toc: true
    latex_engine: "xelatex"
    code_folding: "hide"
editor_options:
  chunk_output_type: console
---
  
```{r 0-setup, include=FALSE, warning=FALSE}
#regular
library(dplyr)
library(data.table)
library(ggplot2)
library(cowplot)
library(qqman)
library(doParallel)

#models tested
library(qgg)
library(varbvs)
library(glmnet)
library(BGLR)

#options
options(bitmapType = "cairo")
options(error = function() traceback(3))

#seed
set.seed(123)

#include r2 for bglr
#add id bank to snakemake data folder

```

The overarching goal of this process is to predict the phenotype for starvation resistance, a continuous trait, by using gene expression data, another continuous trait. This is done using k-fold cross validation to create models based on a subset of the data and calculating the correlation of that model with the remaining partition. By repeating this process multiple times with different training and testing partitions, model bias can be significantly reduced and allows for calculation of average correlation coefficients for each model. The primary difference between the methods in question is the prior distribution used.


```{r setup}

#loop count and data limit
iter <- 50

#ggplot holder list
gg <- vector(mode='list', length=6)

# result storage elements
fit_greml <- vector(mode='list', length=iter)
fit_gbayesC <- vector(mode='list', length=iter)
fit_varbvs <- vector(mode='list', length=iter)
fit_glmnet <- vector(mode='list', length=iter)
fit_bglr <- vector(mode='list', length=iter)

```



The first main set of data used for this analysis is a matrix of gene expression by DGRP line matched to raw starvation resistance. A second cluster of data sets provided by the Morgante Lab includes information on Wolbachia infection status and inversion status by line along with functions to adjust phenotypic values based on these two factors.

```{r expression-data, eval=FALSE, message=FALSE}

 #wolb infection and inversion status data with phenotype adjustment function
load("/data2/morgante_lab/data/dgrp/misc/adjustData.RData")

  #expression data matched to line and starvation phenotype
  xp_f <- fread("data/xp-f.txt")
  
 # xp_m <- fread("data/xp-m.txt")
  
  #setwd("C:/Users/noahk/OneDrive/Desktop/amogus")
  #getwd()
  
  #create matrix of only gene expression, trims line and starvation
  X <- as.matrix(xp_f[,3:11340])
  rownames(X) <- xp_f[,line]
  W <- scale(X)
  
  y_temp <- xp_f[,starvation]
  dat <- data.frame(id=xp_f[,line], y=y_temp)
  y <- adjustPheno(dat, "starvation")


#model to solve for, vector of ones
mu <- matrix(rep(1, length(y)), ncol=1)
#names(mu) <- paste0("line", 1:length(mu))
rownames(mu) <- xp_f[,line]
TRM <- tcrossprod(W)/ncol(W)

# k-fold parameters
n <- length(y)
fold <- 5


```


The matrix containing only gene expression by line data was then scaled to an absolute max of 1. along with this, a Translation Relationship Matrix was generated by taking the crossproduct of the scaled expression matrix and scaling it down by the number of genes.


5 was chosen for k-fold cross validation resulting in 39 lines per validation set and 159 lines per training set.


The following methods are currently implemented:


qgg::greml - Genomic Restricted Maximum Likelihood Estimation using Best Linear Unbiased Predictor. GREML uses a Gaussian prior distribution, performing the least shrinkage and no variable selection.

glmnet - glmnet uses LASSO, or least absolute shrinkage and selection operator. Bayesian LASSO uses a thick-tailed prior which performs greater shrinkage towards the mean than a Gaussian distribution.

qgg::gbayes - BayesC has been implemented using this command. BayesC uses a spike-slab prior which performs variable selection. This intentionally sets the effect of some genes expressed to zero which models the idea that some genes have no effect on the given trait. 

varbvs - Bayesian variable selection performs variable selection using another spike-slab prior. This method avoids Markov Chain Monte Carlo methods by approximating the posterior distribution to reduce computational resources.

BGLR - Bayesian General Linear Regression has the capability to perform BayesC linear regression using a Gibbs Sampler. 


```{r loop_qgg_gbayes, message=FALSE, eval=FALSE}


ids <- readRDS("data/id_bank.Rds")

registerDoParallel(cores = 1)

iter <- 1

i <- 1

corLoop <- foreach(i=1:iter) %dopar% {

  #result holder
  corResult <- rep(0, 5)
  
  #setup train and test sets with trait vectors
  #test_IDs <- sample(1:n, as.integer(n / fold))
  
  test_IDs <- unlist(ids[i])
  
  W_train <- W[-test_IDs,]
  W_test <- W[test_IDs,]
  y_train <- y[-test_IDs]
  y_test <- y[test_IDs]
  
   ### BGLR
  fitBGLR <- BGLR::BGLR(y_train, response_type = "gaussian", a=NULL, b=NULL,ETA = list(list(X=W_train, model="BayesC")), nIter = 500, burnIn = 200)
  
  y_calc <- predict(fitBGLR, W_test)
  
  corResult[5] <- cor(y_test, y_calc)
  
  length(y_calc)
  length(y_test)
  
  #Overall result
  corResult

}

  



corLoop <- foreach(i=1:iter) %dopar% {

  #result holder
  corResult <- rep(0, 5)
  
  #setup train and test sets with trait vectors
  #test_IDs <- sample(1:n, as.integer(n / fold))
  
  test_IDs <- unlist(ids[i])
  
  W_train <- W[-test_IDs,]
  W_test <- W[test_IDs,]
  y_train <- y[-test_IDs]
  y_test <- y[test_IDs]
  

  ### QGG::GREML
  fitGreml <- qgg::greml(y=y, X=mu, GRM=list(A=TRM), validate = matrix(test_IDs,ncol=1), verbose=FALSE)
  
  corResult[1] <- fitGreml$accuracy$Corr
  
  ### QGG::GBAYES-C
  fitC <- qgg::gbayes(y=y_train, W=W_train, method="bayesC", scaleY=FALSE, nit=50000, nburn=20000)
  
  # \hat{y}_test = W_{test} * \hat{b} + \hat{mu}
  y_calc <- W_test %*% fitC$b + mean(y_train)
  corResult[2] <- cor(y_test, y_calc)

  ### VARBVS
  fitVarb <- varbvs::varbvs(X = W_train, NULL, y=y_train, family = "gaussian", logodds=seq(-3.5,-1,0.1), sa = 1, verbose=TRUE)
  
  y_calc <- predict(fitVarb, X=W_test)
  corResult[3] <- cor(y_test, y_calc)
  
  ### GLMNET::LASSO
  fitlm <- glmnet::cv.glmnet(x=W_train, y=y_train, alpha=1)
  
  y_calc <- predict(fitlm, W_test, s="lambda.min")
  corResult[4] <- cor(y_test, y_calc)
  
  ### BGLR
  fitBGLR <- BGLR::BGLR(y_train, response_type = "gaussian", a=NULL, b=NULL,ETA = list(list(X=W_train, model="BayesC")), nIter = 50000, burnIn = 20000)
  
  y_calc <- predict(fitBGLR, W_test)
  corResult[5] <- cor(y_test, y_calc)
  
  #Overall result
  corResult

}



```



```{r listConversion-f}

iter <- 50
# results loaded from correlation loop structure
bayesF <- readRDS("data/bayesF.rds")
corLoop <- readRDS("data/corLoop-f-minus.rds")
bglrLoop <- readRDS("data/bglr-f-130k.rds")

for(i in 1:iter){
  fit_greml[[i]] <- corLoop[[i]][1]
  fit_gbayesC[[i]] <- bayesF[[i]][1]
  fit_varbvs[[i]] <- corLoop[[i]][2]
  fit_glmnet[[i]] <- corLoop[[i]][3]
  fit_bglr[[i]] <- bglrLoop[[i]][5]
}

temp <- c(unlist(fit_greml), unlist(fit_gbayesC), unlist(fit_varbvs), unlist(fit_glmnet), unlist(fit_bglr))

label <- c(rep("greml", iter), rep("gBayesC", iter), rep("varbvs", iter), rep("glmnet", iter), rep("bglr", iter)) 

data <- data.table(cor=as.numeric(temp), method=label)

gg[[1]] <- ggplot(data, aes(x=method, y=cor, fill=method)) +
  geom_boxplot() +
  ggtitle("Female Correlations Boxplot") +
  labs(x="Method", y="Correlation Coefficient") +
  stat_summary(fun=mean, color="black", geom="point", 
               shape=18, size=3, show.legend=FALSE) 


```


```{r listConversion-m}

# results loaded from correlation loop structure
bayesM <- readRDS("data/bayesM.rds")
corLoop <- readRDS("data/corLoop-m-Minus.rds")
bglrLoop <- readRDS("data/bglr-m-130k.rds")

for(i in 1:iter){
  fit_greml[[i]] <- corLoop[[i]][1]
  fit_gbayesC[[i]] <- bayesM[[i]][1]
  fit_varbvs[[i]] <- corLoop[[i]][2]
  fit_glmnet[[i]] <- corLoop[[i]][3]
  fit_bglr[[i]] <- bglrLoop[[i]][5]
}

temp <- c(unlist(fit_greml), unlist(fit_gbayesC), unlist(fit_varbvs), unlist(fit_glmnet), unlist(fit_bglr))

label <- c(rep("greml", iter), rep("gBayesC", iter), rep("varbvs", iter), rep("glmnet", iter), rep("bglr", iter)) 

data <- data.table(cor=as.numeric(temp), method=label)

gg[[2]] <- ggplot(data, aes(x=method, y=cor, fill=method)) +
  geom_boxplot() +
  ggtitle("Male Correlations Boxplot") +
  labs(x="Method", y="Correlation Coefficient") +
  stat_summary(fun=mean, color="black", geom="point", 
               shape=18, size=3, show.legend=FALSE) 

```


```{r snakeData}
### FEMALE
iter <- 50

bglr <- readRDS("snake/data/2_cor/bglr_f_starvation.Rds")
lasso <- readRDS("snake/data/2_cor/lasso_f_starvation.Rds")
rr <- readRDS("snake/data/2_cor/rr_f_starvation.Rds")
varbvs <- readRDS("snake/data/2_cor/varbvs_f_starvation.Rds")

temp <- c(varbvs, lasso, rr, bglr)

label <- c(rep("varbvs", iter), rep("lasso", iter), rep("rr", iter), rep("bglr", iter)) 

data <- data.table(cor=as.numeric(temp), method=label)

gg[[3]] <- ggplot(data, aes(x=method, y=cor, fill=method)) +
  geom_boxplot() +
  ggtitle("Female Correlations Boxplot") +
  labs(x="Method", y="Correlation Coefficient") +
  stat_summary(fun=mean, color="black", geom="point", 
               shape=18, size=3, show.legend=FALSE)

### MALE
bglr <- readRDS("snake/data/2_cor/bglr_m_starvation.Rds")
lasso <- readRDS("snake/data/2_cor/lasso_m_starvation.Rds")
rr <- readRDS("snake/data/2_cor/rr_m_starvation.Rds")
varbvs <- readRDS("snake/data/2_cor/varbvs_m_starvation.Rds")
path
temp <- c(varbvs, lasso, rr, bglr)
label <- c(rep("varbvs", iter), rep("lasso", iter), rep("rr", iter), rep("bglr", iter)) 
data <- data.table(cor=as.numeric(temp), method=label)

gg[[4]] <- ggplot(data, aes(x=method, y=cor, fill=method)) +
  geom_boxplot() +
  ggtitle("Male Correlations Boxplot") +
  labs(x="Method", y="Correlation Coefficient") +
  stat_summary(fun=mean, color="black", geom="point", 
               shape=18, size=3, show.legend=FALSE)

```




### Correlation Coefficient Boxplots





```{r plot-print}

plot_grid(gg[[1]],gg[[2]], ncol=2)

plot_grid(gg[[3]],gg[[4]], ncol=2)

```





